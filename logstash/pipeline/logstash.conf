input {
	beats {
		port => 5044
	}

    # Not used
	# tcp {
	# 	port => 5000
	# }

	http {
		host => "0.0.0.0" # default: 0.0.0.0
		port => 31311 # default: 8080
  	}
}

## Add your filters / logstash plugins configuration here

filter {
# 	# date {
# 	# 	# Need to adapt the timestamp format, Z is timezone?
# 	# 	match => [ "timestamp" , "dd/MMM/yyyy:HH:mm:ss Z" ]
# 	# }
	# Remove HTTP header fields and host of the request that uploads the logdata to logstash
	date {
    	match => [ "timestamp", "ISO8601" ]	# <fieldname, pattern>
		locale => "en_US"	# POSIX
		target => "@timestamp"	# Write timestamp to this field
  	}

	mutate {
		remove_field => ["headers"]
		#remove_field => ["headers", "host"]
	}
}

output {
	# https://www.elastic.co/guide/en/logstash/current/plugins-outputs-elasticsearch.html#plugins-outputs-elasticsearch-http_compression
	elasticsearch {
		hosts => "elasticsearch:9200"			# Elastic host
		user => "elastic"						# Elastic username
		password => "562NmQK60gZcVEATWBIm"		# Elastic password
		ecs_compatibility => "disabled"			# ECS compatibility (https://www.elastic.co/guide/en/ecs/current/index.html) - Some fields have to be set
		# data_stream => true						# Sends data to Elastic via a data stream
        # data_stream_type => "logs"				# Stream type, so logs, metrics etc.
        # data_stream_dataset => "generic"		# ? - generic is just the default value
        # data_stream_namespace => "apodini"		# Namespace of the data stream
		http_compression => true				# Enable HTTP compression
		# #ilm_enabled => true						# Enable Index Lifecycle Management (https://www.elastic.co/guide/en/elasticsearch/reference/7.13/index-lifecycle-management.html)
		# #ilm_pattern => "{now/d}-000001"			# Pattern used for generating indices mangaged by ILM
		# #ilm_policy => "logstash-policy"			# Policy of ILM
		index => "logstash-%{+yyyy.MM.dd}"		# The index to write logs to
		# resurrect_delay => 5					# Timeinterval to wait during sending events to elastic if the cluster appears to be down
		# retry_initial_interval => 2				# Initial interval in seconds between bulk retries
		# retry_max_interval => 64				# Max interval in seconds between bulk retries
		# #retry_on_conflict => 1					# The number of times Elasticsearch should internally retry an update/upserted document
		# timeout => 30							# Timeout for network operations and requests sent Elasticsearch
	}
}
